# Introdu√ß√£o ao Azure Databricks

O **Azure Databricks** √© uma plataforma de an√°lise de dados baseada em Apache Spark, otimizada para a nuvem Azure. Ele combina a performance de alto n√≠vel do Spark com a facilidade de uso de notebooks colaborativos, tornando-se uma ferramenta poderosa para ci√™ncia de dados, engenharia de dados e an√°lise de big data.

Com o Azure Databricks √© poss√≠vel processar grandes volumes de dados de forma distribu√≠da, criar pipelines de dados, treinar modelos de machine learning e visualizar insights em tempo real.

---

## üìå Provisionando um Databricks

![Provisionando Databricks](images/provisionando-databricks.png)

**Descri√ß√£o:**  
Esta tela mostra o processo de cria√ß√£o de um workspace do Databricks no portal do Azure. Nessa etapa, configuramos o nome do recurso, grupo de recursos, regi√£o e plano de pre√ßo. O workspace √© o ambiente central onde clusters e notebooks ser√£o criados e gerenciados.

---

## ‚öôÔ∏è Criando um Cluster

![Criando Cluster](images/criando-cluster.png)

**Descri√ß√£o:**  
Ap√≥s o workspace estar provisionado, o pr√≥ximo passo √© criar um **Cluster**, que √© um conjunto de m√°quinas virtuais configuradas para executar tarefas em Spark. Aqui escolhemos o tipo de inst√¢ncia, o n√∫mero de workers e configura√ß√µes adicionais como o tempo de inatividade autom√°tico.

---

## üîç Usando o Spark para Analisar Dados

![Analisando com Spark](images/usando-spark.png)

**Descri√ß√£o:**  
Com o cluster em execu√ß√£o, √© poss√≠vel criar notebooks e usar **Apache Spark** para leitura, transforma√ß√£o e an√°lise de dados. O exemplo da imagem mostra o uso de comandos em PySpark para ler arquivos CSV, exibir esquemas e realizar queries sobre os dados. Essa etapa √© fundamental para gerar insights a partir de dados brutos no Databricks.

---

## üìÇ Estrutura de Pastas Recomendada

